여긴 아무말 하는 메모장 겸 기록용이라 읽지 않아도 된다.
유튜브 <빵형의 개발도상국>의 가위바위보 기계 만들기 영상을 보고 따라했다.
나도 참 어리석게도 수화를 인식할 수 있는 프로그램을 만들어서 청각장애인들에게 도움을 줄 수 있는 개발자가 되어보자! 라고 대학생때 개발에 관심을 가지게 될 때부터 다짐했던 걸,,, 내 스스로 무지하고 바쁘다는 핑계로 해 볼 엄두조차 내지 못했다.
코드를 짜고 분석하는 것도 좋아하고, 데이터를 가지고서 처리하고 묶고 잘 흘러갈 수 있게 만드는 것도 좋아해서 막연히 데이터를 분석하고 처리하는 사이언티스트나 엔지니어, 아날라이저가 되고싶다고 하고서 비전공자의 개발자 양성과정에 참여했다. 신청한 양성과정도 심지어 데이터 처리 기반 클라우드 엔지니어였고, 클라우드가 뭔지도 모르는 와중에 '데이터 처리'라는 단어에 꽂혀서 지원했다. 물론 아무 생각 없이 지원한 것은 아니고 지원 당시 msa 반도 있었는데 하도 클라우드가 핫하고 찾아보니까 엄청나게 많은 걸 배울 수 있을 것 같아서 클라우드 반을 선택했다.
어쨌든 지금 와서 ELK stack, kafka를 접하고 공부하게 되면서 다시끔 '아 나는 데이터를 다루는 걸 좋아하는 구나' 싶고 더 나아가 흥미를 가지고 있던 인공지능 분야도 공부하고 싶었다. 이게 이유가 될 지는 모르겠지만 그냥 물 흐르게 공부하다 보니 ML을 공부해야겠다 싶었고, 더 나아가 ML로 만은 만족 못하고 이걸 결국은 총체적으로 관리해야 하는 파이프라인 구축이 중요한 걸 알아서 MLOps를 공부하기로 마음 먹었다.(예솔아 나 오늘 마음먹었어. ML 파고들기로...)
쨌든 각설하고 빵형따라서 손 인식 가위바위보 기계 만들기를 따라해보자
우선 single.py 에는 한손을 인식하는 코드를 작성해서 테스트 해본다. 이때 쓸 패키지는 OpenCV-webcam 제어, mediapipe-손 인식, numpy가 있다. 그리고 코드 내에서는 11개의 gesture을 미리 모아둔 걸 학습시켜 두었다고 한다.  그것에 대한 데이터는 data/gesture_train.csv이고
이 가위바위보 기계의 파이프라인은 1.손가락 인식 mediapipe(구글에서 제공하는 신체 대상 비전인식 및 ai모델 개발과 기계학습 제공 서비스) -> 2. 손가락 마디 각도 계산(이건 'https://developers.google.com/mediapipe/solutions/vision/hand_landmarker' 여기 가보면 hand에 대해서 각 joint(붉은 점)에 번호를 매기고, 이 번호들 사이의 각도를 계산해서 수치화 시킴- 이 수치로 손 모양이 어떤 것에 해당하는지 데이터를 남김 - 이게 곧 data/gesture_train에 해당) -> 3. 제스쳐 인식 KNN (KNN은 k 최근접 이웃 알고리즘인데 대학교때 물리화학시간과 생명통계학분석이었나 그 수업에서 배웠는데 이걸 여기서 마주치다니... 그때는 spss였나 그 프로그램 이용하고 데이터 분석하고 그랬는데 줄줄 외우기에 급했다..., 쨌든 기존의 존재하는 데이터와 비교해서 유사도가 높은 k의 데이터로 예측 및 분석- 따로 모델이 필요하지 않음.) -> 4. 승자 결정
virtual box에서 했는데 webcam 연결 안되서(인터넷 찾아봤는데 usb 3.0 설정하라고는 하는데 아예 체크박스가 고정이라...) 그래서 코드들을 로컬로 옮기고 실행해보려고 함.